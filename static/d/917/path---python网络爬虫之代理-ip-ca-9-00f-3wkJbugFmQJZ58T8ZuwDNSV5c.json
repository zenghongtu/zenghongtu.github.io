{"data":{"post":{"id":"0abb1333-d6ee-5c4c-9033-991ceba9cd3d","html":"<p>title: Python网络爬虫之代理IP\nauthor: 大图\ntags:</p>\n<ul>\n<li>python</li>\n<li>代理ip\ncategories:</li>\n<li>\n<p>爬虫\ndate: 2017-04-02 14:55:00</p>\n<hr>\n<p>在爬取数据的过程中，经常会遇到限制IP的情况。降低爬虫的访问频率，可以防止这种情况，当需要快速的爬取数据的时候，这种方式就不适用了，这时候就需要使用代理IP来爬取数据了。</p>\n</li>\n</ul>\n<p>网络上有很多免费代理，经常需要用到代理IP的话，可以爬取一些网站提供的代理，维护一个自己的代理IP池</p>\n<ol>\n<li>\n<p>爬取代理网站\nIPCN</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">def get_from_ipcn():\nurls=[&#39;http://proxy.ipcn.org/proxya.html&#39;,&#39;http://proxy.ipcn.org/proxya2.html&#39;\n,&#39;http://proxy.ipcn.org/proxyb.html&#39;,&#39;http://proxy.ipcn.org/proxyb2.html&#39;]\nfor url in urls:\n    try:\n        html=requests.get(url,timeout=30).text\n    except:\n        continue\n    ips=re.findall(&#39;\\d+\\.\\d+\\.\\d+\\.\\d+:\\d+&#39;,html)</code></pre></div>\n<p>西刺代理</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">def get_from_xicidaili():\nurls=[&#39;http://www.xicidaili.com/nn/&#39;,&#39;http://www.xicidaili.com/nn/2&#39;\n    ,&#39;http://www.xicidaili.com/wn/&#39;]\nfor pageurl in urls:\n    try:\n        html=requests.get(pageurl,headers=headers,timeout=30).text\n    except:\n        continue\n    table=BeautifulSoup(html,&#39;lxml&#39;).find(&#39;table&#39;,id=&#39;ip_list&#39;).find_all(&#39;tr&#39;)\n    iplist=[]\n    for tr in table[1:]:\n        tds=tr.find_all(&#39;td&#39;)\n        ip=tds[1].get_text()+&#39;:&#39;+tds[2].get_text()\n        iplist.append(ip)</code></pre></div>\n<p>开心代理</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">def get_from_kxdaili():\nurls=[&#39;http://www.kxdaili.com/dailiip/1/%s.html&#39;,&#39;http://www.kxdaili.com/dailiip/3/%s.html&#39;]\nfor url in urls:\n    page=1\n    while page&lt;=10:\n        try:\n            html=requests.get(url%(page),headers=headers,timeout=30).text.encode(&#39;ISO-8859-1&#39;).decode(&#39;utf-8&#39;,&#39;ignore&#39;)\n            page+=1\n        except:\n            continue\n        try:\n            table=BeautifulSoup(html,&#39;lxml&#39;).find(&#39;table&#39;).find_all(&#39;tr&#39;)\n        except:\n            continue\n        iplist=[]\n        for tr in table[1:]:\n            tds=tr.find_all(&#39;td&#39;)\n            ip=tds[0].get_text()+&#39;:&#39;+tds[1].get_text()\n            iplist.append(ip)</code></pre></div>\n</li>\n<li>验证代理\n验证代理是否可用，可用则添加进数据库。这里通过 <a href=\"http://httpbin.org/ip\">http://httpbin.org/ip</a> 这个网站验证IP是否高匿可用。</li>\n</ol>\n<p>如果IP高匿可用，则查询的IP与使用的代理IP吻合。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">class IsEnable(threading.Thread):\n    def __init__(self,ip):\n        super(IsEnable,self).__init__()\n        self.ip=ip\n        self.proxies={\n        &#39;http&#39;:&#39;http://%s&#39;%ip\n        }\n\n    def run(self):\n        try:\n            html=requests.get(&#39;http://httpbin.org/ip&#39;,proxies=self.proxies,timeout=5).text\n            result=eval(html)[&#39;origin&#39;]\n            if len(result.split(&#39;,&#39;))==2:\n                return\n            if result in self.ip:\n                self.insert_into_sql()\n        except:\n            return\n\n    def insert_into_sql(self):\n        conn=sqlite3.connect(&#39;sqldb.db&#39;)\n        cursor=conn.cursor()\n        try:\n            date=time.strftime(&#39;%Y-%m-%d %X&#39;, time.localtime() )\n            cursor.execute(&quot;insert into enableips(ip,date) values(?,?)&quot;,(self.ip,date,))\n            print(self.ip)\n        except:\n            conn.close()\n            return\n        cursor.close()\n        conn.commit()\n        conn.close()</code></pre></div>\n<ol start=\"3\">\n<li>\n<p>维护IP池\n定时更新数据库，剔除不可用IP</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> requests\n<span class=\"token keyword\">import</span> sqlite3\n<span class=\"token keyword\">import</span> threading\n<span class=\"token keyword\">import</span> time</code></pre></div>\n</li>\n</ol>\n<p>headers = {\n“Accept”: “text/html,application/xhtml+xml,application/xml;q=0.9,<em>/</em>;q=0.8”,\n“Accept-Encoding”: “gzip, deflate”,\n“Accept-Language”: “en-US,en;q=0.5”,\n“Connection”: “keep-alive”,\n“User-Agent”: “Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:39.0) Gecko/20100101 Firefox/39.0”}</p>\n<p>class IsEnable(threading.Thread):\ndef <strong>init</strong>(self,ip):\nsuper(IsEnable,self).<strong>init</strong>()\nself.ip=ip\nself.proxies={\n‘http’:’<a href=\"http://%25s&#x27;%25ip\">http://%s’%ip</a>\n}</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">def run(self):\n    try:\n        html=requests.get(&#39;http://httpbin.org/ip&#39;,proxies=self.proxies,timeout=5).text\n        result=eval(html)[&#39;origin&#39;]\n        if len(result.split(&#39;,&#39;))==2:\n            return\n        if result in self.ip:\n            self.update()\n    except:\n        self.delete()\n    return\n\ndef update(self):\n    conn=sqlite3.connect(&#39;sqldb.db&#39;)\n    cursor=conn.cursor()\n    date=time.strftime(&#39;%Y-%m-%d %X&#39;, time.localtime())\n    cursor.execute(&quot;update enableips set date=? where ip=?&quot;,(date,self.ip,))\n    cursor.close()\n    conn.commit()\n    conn.close()\n\ndef delete(self):\n    conn=sqlite3.connect(&#39;sqldb.db&#39;)\n    cursor=conn.cursor()\n    cursor.execute(&quot;delete from enableips where ip=?&quot;,(self.ip,))\n    print(&#39;delete &#39;,self.ip)\n    cursor.close()\n    conn.commit()\n    conn.close()</code></pre></div>\n<p>def verify():\nconn=sqlite3.connect(‘sqldb.db’)\ncursor=conn.cursor()\nrows=cursor.execute(‘select * from enableips’)\niplist=[]\nfor row in rows:\niplist.append(row[0])\nthreadings=[]\nfor ip in iplist:\nwork=IsEnable(ip)\nwork.setDaemon(True)\nthreadings.append(work)\nfor work in threadings:\nwork.start()\nfor work in threadings:\nwork.join()</p>\n<p>if <strong>name</strong> == ’<strong>main</strong>’:\nwhile True:\nverify()\ntime.sleep(600)</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>","fields":{"slug":"/Python网络爬虫之代理IP/","prefix":null},"frontmatter":{"title":"","author":null,"category":null,"cover":null}},"authornote":{"id":"f3ffdeef-a16f-507d-9f2f-98fa5e045d0b","html":"<p><strong>Mr. Gatsby</strong> Proin ornare ligula eu tellus tempus elementum. Aenean <a href=\"/\">bibendum</a> iaculis mi, nec blandit lacus interdum vitae. Vestibulum non nibh risus, a scelerisque purus. Blandit lacus interdum vitae. Vestibulum non nibh risus, a scelerisque purus.</p>"},"site":{"siteMetadata":{"facebook":{"appId":""}}}},"pageContext":{"slug":"/Python网络爬虫之代理IP/","next":{"id":"2a2f6e49-4eab-5bc6-b9ea-2b168e79c943","fields":{"slug":"/python网络爬虫之人人贷散标数据抓取/","prefix":null,"source":"posts"},"frontmatter":{"title":"","category":null}},"source":"posts"}}